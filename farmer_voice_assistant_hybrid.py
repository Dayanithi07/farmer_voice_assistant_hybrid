# farmer_voice_assistant_hybrid.py

import streamlit as st
from PIL import Image
import requests
from transformers import AutoProcessor, AutoModelForImageClassification, pipeline
import torch
from gtts import gTTS
import tempfile
import io
import geocoder
import speech_recognition as sr

# -----------------------------
# 1я╕ПтГг Streamlit Config
# -----------------------------
st.set_page_config(
    page_title="рокропро┐ро░рпН роЙродро╡ро┐ропро╛ро│ро░рпН",
    layout="centered",
    initial_sidebar_state="collapsed"
)

st.markdown("""
<style>
body { background-color: #fdfdfd; color: #000000; }
.stButton>button { background-color: #4CAF50; color: white; }
</style>
""", unsafe_allow_html=True)

# -----------------------------
# 2я╕ПтГг Load Plant Disease Model
# -----------------------------
model_name = "linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification"
processor = AutoProcessor.from_pretrained(model_name)
model = AutoModelForImageClassification.from_pretrained(model_name)
class_labels = {0:"Healthy",1:"Diseased - Class 1",2:"Diseased - Class 2"}  # replace with full labels

# -----------------------------
# 3я╕ПтГг Hugging Face GPT Fallback
# -----------------------------
hf_gpt_pipe = pipeline("text-generation", model="tiiuae/falcon-7b-instruct", device=-1)

# -----------------------------
# 4я╕ПтГг Helper Functions
# -----------------------------
def speak(text):
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tts = gTTS(text=text, lang='ta')
    tts.save(tmp.name)
    return tmp.name

def is_connected():
    try:
        requests.get("https://www.google.com", timeout=3)
        return True
    except:
        return False

def gpt_response_hybrid(user_text):
    if is_connected():
        try:
            import openai
            openai.api_key = "AIzaSyAU2sKsiu63mPjzMtSH5DhG7_8beUr5F7c"
            response = openai.chat.completions.create(
                model="gemini-1.5-t",
                messages=[
                    {"role": "system", "content": "You are a helpful Tamil-speaking farming assistant."},
                    {"role": "user", "content": user_text}
                ],
                temperature=0.7
            )
            reply_text = response.choices[0].message.content
        except:
            # fallback to Hugging Face GPT if Gemini fails
            output = hf_gpt_pipe(f"Respond in Tamil in a farmer-friendly way:\n{user_text}", max_length=200)
            reply_text = output[0]['generated_text']
    else:
        # offline fallback
        output = hf_gpt_pipe(f"Respond in Tamil in a farmer-friendly way:\n{user_text}", max_length=200)
        reply_text = output[0]['generated_text']

    audio_file = speak(reply_text)
    return reply_text, audio_file

def get_location():
    try:
        g = geocoder.ip('me')
        if g.ok:
            return g.latlng
        return [20.5937, 78.9629]
    except:
        return [20.5937, 78.9629]

def get_weather(lat, lon):
    api_key = "e972e190876a2d130682da01b94f8a80"
    url = f"http://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}&units=metric"
    try:
        response = requests.get(url).json()
        weather_desc = response['weather'][0]['description']
        temp = response['main']['temp']
        return f"{weather_desc}, ро╡рпЖрокрпНрокроиро┐ро▓рпИ: {temp}┬░C"
    except:
        return "ро╡ро╛ройро┐ро▓рпИ родро░ро╡рпБ роХро┐роЯрпИроХрпНроХро╡ро┐ро▓рпНро▓рпИ"

def get_soil(lat, lon):
    try:
        url = f"https://soilgrids.org/query?lon={lon}&lat={lat}&attributes=bdod,cec,phh2o,ocd"
        response = requests.get(url).json()
        data = response['properties']['layers']
        soil_info = f"BDOD={data['bdod']['values']['mean']}, CEC={data['cec']['values']['mean']}, pH={data['phh2o']['values']['mean']}, Organic Carbon={data['ocd']['values']['mean']}"
        return soil_info
    except:
        return "роорогрпН родроХро╡ро▓рпН роХро┐роЯрпИроХрпНроХро╡ро┐ро▓рпНро▓рпИ"

def detect_disease(image_file):
    img_bytes = image_file.read()
    img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
    inputs = processor(images=img, return_tensors="pt")
    with torch.no_grad():
        logits = model(**inputs).logits
    predicted_idx = logits.argmax(-1).item()
    return class_labels.get(predicted_idx, "Unknown")

def analyze_crop(image_file):
    lat, lon = get_location()
    disease_name = detect_disease(image_file)
    weather_summary = get_weather(lat, lon)
    soil_summary = get_soil(lat, lon)

    detailed_audio_text = f"""
ро╡рогроХрпНроХроорпН! роЙроЩрпНроХро│рпН рокропро┐ро░рпН родро▒рпНрокрпЛродрпИроп роиро┐ро▓рпИропрпИ роиро╛ройрпН рокро╛ро░рпНроХрпНроХро┐ро▒рпЗройрпН.
рокродро┐ро╡рпЗро▒рпНро▒рокрпНрокроЯрпНроЯ рокрпБроХрпИрокрпНрокроЯродрпНродро┐ройрпН рокроЯро┐, роирпЛропрпН: {disease_name}.
роЙроЩрпНроХро│рпН рокроХрпБродро┐ропро┐ро▓рпН родро▒рпНрокрпЛродрпИроп ро╡ро╛ройро┐ро▓рпИ: {weather_summary}.
роорогрпН ро╡ро┐ро╡ро░роЩрпНроХро│рпН: {soil_summary}.
рокропро┐ро░рпИ роЪро░ро┐ропро╛роХ рокро░ро╛рооро░ро┐роХрпНроХ родрпЗро╡рпИропро╛рой роироЯро╡роЯро┐роХрпНроХрпИроХро│рпН: роЙроЩрпНроХро│рпН рокропро┐ро░ро┐ройрпН роирпЛропрпИ роХро╡ройро┐родрпНродрпБ рооро░рпБроирпНродрпБ ро╡ро┐родро┐роХрпНроХро╡рпБроорпН, роирпАро░рпН роЕро│ро╡рпИ роЪро░ро┐роЪрпЖропрпНропро╡рпБроорпН, роЪрпЖро╡рпНро╡ро┐ропро▓рпН роорпБро▒рпИропро┐ро▓рпН роЙро░роорпН роЪрпЗро░рпНроХрпНроХро╡рпБроорпН.
"""
    audio_file = speak(detailed_audio_text)
    return disease_name, weather_summary, soil_summary, audio_file

def speech_to_text():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("родропро╡рпБроЪрпЖропрпНродрпБ рокрпЗроЪрпБроЩрпНроХро│рпН...")
        audio = r.listen(source, phrase_time_limit=10)
    try:
        text = r.recognize_google(audio, language="ta-IN")
        return text
    except:
        return None

# -----------------------------
# 5я╕ПтГг App Layout
# -----------------------------
st.title("ЁЯМ┐ рокропро┐ро░рпН роЙродро╡ро┐ропро╛ро│ро░рпН (Hybrid Voice Assistant)")
st.write("рокрпБроХрпИрокрпНрокроЯроорпН рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН / роХрпЗро│рпНро╡ро┐роХро│рпН роХрпЗро│рпБроЩрпНроХро│рпН. роЙроЩрпНроХро│рпН роХрпЗро│рпНро╡ро┐роХрпНроХрпБ AI родрооро┐ро┤ро┐ро▓рпН рокродро┐ро▓рпН роХрпВро▒рпБроорпН.")

# Voice greeting
if 'greeted' not in st.session_state:
    welcome_audio = speak("ро╡рогроХрпНроХроорпН! роиро╛ройрпН роЙроЩрпНроХро│рпН рокропро┐ро░рпН роЙродро╡ро┐ропро╛ро│ро░рпН. рокрпБроХрпИрокрпНрокроЯроорпН рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН роЕро▓рпНро▓родрпБ роХрпЗро│рпНро╡ро┐ роХрпЗро│рпБроЩрпНроХро│рпН.")
    st.audio(welcome_audio)
    st.session_state.greeted = True

# Image upload / camera capture
uploaded_file = st.file_uploader("рокропро┐ро░рпН рокрпБроХрпИрокрпНрокроЯроорпН рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН", type=["jpg","jpeg","png"])
capture_image = st.camera_input("рокропро┐ро░рпН рокрпБроХрпИрокрпНрокроЯроорпН роОроЯрпБроХрпНроХро╡рпБроорпН")
image_to_use = uploaded_file if uploaded_file else capture_image

if image_to_use:
    disease_name, weather_summary, soil_summary, audio_file = analyze_crop(image_to_use)
    
    st.subheader("ЁЯФ╣ роирпЛропрпН роорпБройрпНройро▒ро┐роХрпНроХрпИ")
    st.write(disease_name)
    
    st.subheader("ЁЯФ╣ ро╡ро╛ройро┐ро▓рпИ")
    st.write(weather_summary)
    
    st.subheader("ЁЯФ╣ роорогрпН родроХро╡ро▓рпН")
    st.write(soil_summary)
    
    st.audio(audio_file)

# Real-time voice input
st.subheader("ЁЯОд роЙроЩрпНроХро│рпН роХрпЗро│рпНро╡ро┐ рокрпЗроЪрпБроЩрпНроХро│рпН")
if st.button("роЪрпЖропро▓рпНрокроЯрпБродрпНрод"):
    spoken_text = speech_to_text()
    if spoken_text:
        st.write(f"роирпАроЩрпНроХро│рпН рокрпЗроЪро┐ропродрпБ: {spoken_text}")
        reply_text, audio_file = gpt_response_hybrid(spoken_text)
        st.write(reply_text)
        st.audio(audio_file)
    else:
        st.error("рооро┐роХро╡рпБроорпН рооройрпНройро┐роХрпНроХро╡рпБроорпН, роЙроЩрпНроХро│рпН роХрпБро░ро▓рпН роЕро▒ро┐ропрокрпНрокроЯро╡ро┐ро▓рпНро▓рпИ. рооро▒рпБрокроЯро┐ропрпБроорпН роорпБропро▒рпНроЪро┐роХрпНроХро╡рпБроорпН.")
